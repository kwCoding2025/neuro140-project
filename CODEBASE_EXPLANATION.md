# Codebase Explanation: FloorplanCAD Processing and Modeling

<!-- Generated by AI Assistant -->

This document provides a detailed walkthrough of the codebase, explaining the workflow from initial data download to final results analysis for the FloorplanCAD dataset processing and modeling task. It also identifies areas of redundancy and evaluates the quality of comments.

## Overall Workflow

The pipeline follows these general steps:

1.  **Data Acquisition (`download.py`)**: Downloads compressed floorplan SVG data from Kaggle.
2.  **Data Preprocessing (`convert_svg.py`)**: Converts raw SVG files into PNG images and extracts structured path/layer data into JSON and Pickle files.
3.  **Training (`src/train.py`)**: Trains a model (ResNet50 or ViT) to predict room count, wall count, and wall coordinates from floorplan images using the preprocessed data.
4.  **Evaluation (`src/evaluate.py`)**: Evaluates the trained model on a test set, calculating basic error metrics and a composite score.
5.  **Best Checkpoint Selection (`find_best_checkpoints.py`)**: Identifies the model checkpoint with the best validation loss during training.
6.  **Results Analysis (`analyze_results.py`)**: Performs a more detailed comparison and analysis of the evaluation results, generating plots.

## Detailed File Breakdown

### 1. Data Acquisition (`download.py`)

*   **Purpose**: Downloads specific `.tar.xz` archives from the `catwhisker/floorplancad-dataset` on Kaggle. Extracts only the `.svg` files into `./floorplancad-dataset/`, maintaining the original train/test split structure found within the archives.
*   **Process**: Uses the Kaggle API (via `subprocess`) after setting up credentials. Extracts SVG files using the `tarfile` library.
*   **Key Issues**:
    *   **(HIGH SEVERITY) Hardcoded Credentials**: Kaggle username and API key are hardcoded directly in the script (`setup_kaggle_credentials`). This is a major security risk. Credentials should be loaded securely (e.g., environment variables, config file).
    *   **Redundant Download Check**: Only checks for the existence of the *downloaded archive* (`.tar.xz`), not the *extracted SVGs*. Could lead to re-downloads if `downloaded_data/` is cleared but `floorplancad-dataset/` remains.
*   **Comments**: Present but fail to warn about the hardcoded credentials security risk.

### 2. Data Preprocessing (`convert_svg.py`)

*   **Purpose**: Processes raw `.svg` files from `./floorplancad-dataset/`. Converts each to a PNG image and extracts structured path, layer, and text data, saving it into `./floorplancad-processed/` within `images/`, `json/`, and `pkl/` subdirectories.
*   **Process**: Uses `cairosvg` for PNG rendering, `xml.etree.ElementTree` for SVG parsing, and `svgpathtools` for path data interpretation. Samples points along paths and extracts metadata. Uses `ProcessPoolExecutor` for parallelism.
*   **Key Issues**:
    *   **Arbitrary Path Sampling**: Samples exactly 100 points per path (`range(100)`). This might be inefficient for simple paths or insufficient for complex ones. Consider adaptive sampling or making it configurable.
    *   **Error Handling**: Path parsing errors are logged but result in empty `points` data, potentially ignoring useful information silently.
*   **Comments**: Generally good docstrings and section comments. The comment on path sampling explains *what* but not *why* 100 points were chosen.

### 3. Model Definition (`src/models.py`)

*   **Purpose**: Defines the primary `CompositeModel` used for predictions.
*   **Process**: `CompositeModel` uses a pre-trained backbone (ResNet50 or ViT) followed by a custom regression head predicting `room_count`, `wall_count`, and `wall_coords` (fixed size 200). Includes logic for freezing/unfreezing ViT layers during fine-tuning.
*   **Key Issues**:
    *   **(HIGH SEVERITY) Redundancy**: This file defines `CompositeModel`, but almost identical definitions exist in `src/train.py` and `src/evaluate.py`. This is highly redundant and prone to inconsistencies. This should be the *only* location for this definition.
    *   **ViT Implementation Discrepancy**: The ViT implementation here uses `ViTForImageClassification` and `.logits`, while the redundant definition in `train.py` uses `ViTModel` and `.last_hidden_state[:, 0]`. These approaches differ and need consolidation (the `ViTModel` approach is generally more standard for custom heads).

### 4. Data Loading (`src/utils/data.py`)

*   **Purpose**: Defines the `FloorplanDataset` class used by `train.py` and `evaluate.py` (and `analyze_results.py`) to load data for the model.
*   **Process**: Reads `.pkl` files generated by `convert_svg.py`. Extracts target features (`room_count`, `wall_count`, `wall_coords`) using heuristics (wall intersection counting for rooms, coordinate padding/truncation). *Crucially, it re-renders SVGs to PNGs on the fly during data loading.*
*   **Key Issues**:
    *   **(HIGH SEVERITY) Gross Inefficiency**: The dataset **re-renders SVGs to PNGs** using `cairosvg` inside `__getitem__`. This is extremely slow and unnecessary, as PNGs were already generated by `convert_svg.py`. It should load the pre-existing PNG files from `./floorplancad-processed/images/`.
    *   **(HIGH SEVERITY) Redundancy**: An almost identical `FloorplanDataset` definition exists within `src/train.py`. The definition in `train.py` should be removed.
    *   **Redundant Helper**: Defines `_line_intersection` and `_line_intersection_point` with identical code. One should be removed.
    *   **Heuristic Accuracy**: The `room_count` estimation based on wall intersections (`len(intersections) // 3`) is a potentially inaccurate heuristic. Its reliability should be evaluated.
*   **Comments**: Code has comments, but doesn't highlight the major inefficiency or justify the room count heuristic.

### 5. Training (`src/train.py`)

*   **Purpose**: Main script to train the `CompositeModel`.
*   **Process**: Handles data splitting (train/val/test, saving splits to `.pkl`), model initialization, optimizer setup (Adam), TensorBoard logging, training/validation loops, custom weighted loss calculation, gradient accumulation, checkpoint saving (including `val_loss`), and resuming from checkpoints. Uses directories on network storage (`/n/netscratch/...`).
*   **Key Issues**:
    *   **(HIGH SEVERITY) Redundant Model Definition**: Contains a near-duplicate definition of `CompositeModel`. Should import from `src.models`.
    *   **(HIGH SEVERITY) Redundant Dataset Definition**: Contains a near-duplicate definition of `FloorplanDataset`. Should import from `src.utils.data`.
    *   **Hardcoded Paths/Parameters**: Network storage paths and loss weights (`LOSS_WEIGHTS`) are hardcoded. These should be configurable.
    *   **AI Remnants**: Contains comments like `// Add this import at the top` indicating previous AI editing.
*   **Comments**: Generally okay, but need cleanup and better justification for choices like loss weights.

### 6. Evaluation (`src/evaluate.py`)

*   **Purpose**: Loads a trained checkpoint (`_best.pt` or specific epoch) and evaluates it on the test set.
*   **Process**: Loads test data using `FloorplanDataset` (imported from `src.utils.data`), loads the model checkpoint (handling `module.` prefix), calculates mean absolute errors for outputs, computes a composite score (using different weights than training), saves metrics and raw predictions to JSON files. Includes unused helper functions for converting predictions back to SVG-like format.
*   **Key Issues**:
    *   **(HIGH SEVERITY) Redundant Model Definition**: Contains another near-duplicate definition of `CompositeModel`. Should import from `src.models`.
    *   **Inconsistent Weights**: Uses different weights for the composite score calculation (`0.4, 0.4, 0.2`) compared to the training loss (`0.5, 0.4, 0.1`). This difference should be justified or reconciled.
    *   **Output Format**: Saves raw numerical predictions. Saving the structured JSON from the unused `predictions_to_json` might be more useful.
    *   **AI Remnants**: Contains comments like `# Import your FloorplanDataset (keep this import)`.
*   **Comments**: Okay, but needs AI comment cleanup.

### 7. Best Checkpoint Selection (`find_best_checkpoints.py`)

*   **Purpose**: Finds the epoch checkpoint (`*_epoch_*.pt`) with the lowest validation loss and copies it to `<model_name>_best.pt`.
*   **Process**: Globs checkpoints, loads them (CPU), reads `val_loss`, finds the minimum, and copies the corresponding file using `shutil.copy2`.
*   **Key Issues**: None significant; the script is straightforward and functional.
*   **Comments**: Clear and adequate.

### 8. Results Analysis (`analyze_results.py`)

*   **Purpose**: Provides more detailed analysis and comparison between ResNet50 and ViT models based on evaluation results.
*   **Process**: Loads validation losses from epoch checkpoints, loads evaluation predictions (from the single JSON file produced by `evaluate.py`), re-calculates ground truth features using `FloorplanDataset._extract_features`, performs detailed comparison (MAE, accuracy metrics), and generates comparative plots (loss curves, error distributions).
*   **Key Issues**:
    *   **Incorrect Prediction Loading Logic**: The `load_predictions` function incorrectly assumes predictions are stored in *multiple* `prediction_*.json` files, whereas `evaluate.py` saves them in a *single* `<model_name>_predictions.json` file. This function needs to be corrected.
    *   **Ground Truth Recalculation**: Needs to recalculate ground truth because it wasn't saved by `evaluate.py`. This is slightly inefficient but necessary given the current pipeline.
    *   **Path Hack**: Uses `sys.path.insert` for importing, which works but is less clean.
*   **Comments**: Generally good, explain the steps well.

## Summary of Redundancy

*   **`CompositeModel` Definition**: Defined redundantly in `src/models.py`, `src/train.py`, and `src/evaluate.py`. Should exist ONLY in `src/models.py`.
*   **`FloorplanDataset` Definition**: Defined redundantly in `src/utils/data.py` and `src/train.py`. Should exist ONLY in `src/utils/data.py`.
*   **Line Intersection Helper**: Defined twice (`_line_intersection`, `_line_intersection_point`) with identical code in `src/utils/data.py`. One should be removed.

## Summary of Comments

*   **General Quality**: Mostly acceptable, with docstrings and comments explaining the *what* in many places.
*   **Insufficient Justification**: Comments often lack the *why* behind specific choices (e.g., 100 points for path sampling, room count heuristic, loss weights, evaluation score weights).
*   **AI Remnants**: Several files (`train.py`, `evaluate.py`) contain leftover comments from AI interactions (e.g., `# Add this import`, `# keep this import`) that should be removed.
*   **Missed Critical Issues**: No comments highlight the severe inefficiency in `FloorplanDataset` or the security risk of hardcoded credentials in `download.py`.

## Key Improvement Suggestions

1.  **Fix Data Loading**: Modify `FloorplanDataset` in `src/utils/data.py` to load pre-rendered PNGs, eliminating the major performance bottleneck.
2.  **Consolidate Definitions**: Remove redundant definitions of `CompositeModel` and `FloorplanDataset` from `train.py` and `evaluate.py`. Ensure `src/models.py` and `src/utils/data.py` contain the single source of truth, and resolve the ViT implementation discrepancy in `CompositeModel`. Remove the duplicate line intersection helper in `src/utils/data.py`.
3.  **Remove Hardcoded Credentials**: Modify `download.py` to load Kaggle credentials securely from environment variables or a config file.
4.  **Correct `analyze_results.py`**: Fix the `load_predictions` function to correctly load the single JSON file produced by `evaluate.py`.
5.  **Review Heuristics/Weights**: Evaluate the accuracy of the room count heuristic. Justify or align the weights used in the training loss and the evaluation composite score.
6.  **Configuration**: Make hardcoded paths (especially network paths) and parameters (loss weights, image size, path sampling points) configurable via command-line arguments or a configuration file.
7.  **Clean Up Comments**: Remove AI remnants and add justifications for non-obvious design choices. Add warnings for critical sections if necessary (e.g., efficiency implications if the data loading isn't fixed). 